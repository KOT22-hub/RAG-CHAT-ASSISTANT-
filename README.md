# RAG-CHAT-ASSISTANT-
RAG CHAT Assistant powered by Ollama with Vector Search !

A Retrival Augmentaed Generation (RAG) chat assistant that works by combining vector search with large language models to deliver context aware answers.
Built with Node.js, PostgreSQL + pgvector, Ollama LLMs, and a responsive frontend.

üõ† Tech Stack
| Layer          | Technology                                                        |
| -------------- | ----------------------------------------------------------------- |
| Backend        | Node.js, Express                                                  |
| AI             | Ollama (`gemma3:1b` for chat, `nomic-embed-text` for embeddings)  |
| Database       | PostgreSQL + `pgvector` using Docker                               |
| Frontend       | Vanilla JS, HTML, CSS (interactive chat, Markdown, responsive UI) |
| Deployment     | Docker-ready                                                      |
| Env Management | dotenv                                                            |

üìê Architecture Overview
User Input
   ‚Üì
Frontend (Browser)
   ‚Üì
POST /api/chat ‚Üí Backend (Express)
   ‚Üì
1Ô∏è‚É£ Generate embedding for prompt (Ollama)
2Ô∏è‚É£ Retrieve top N similar conversations (Postgres + pgvector)
3Ô∏è‚É£ Build context for AI model
4Ô∏è‚É£ Send prompt + context to Ollama chat
   ‚Üì
Response returned to frontend
   ‚Üì
Conversation saved to Postgres


